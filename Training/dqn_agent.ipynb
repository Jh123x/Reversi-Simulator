{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c1d372",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf774c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.13.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imageio) (1.21.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imageio) (8.4.0)\n",
      "Requirement already satisfied: PILLOW in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.4.0)\n",
      "Requirement already satisfied: pyglet in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.21)\n",
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2)\n",
      "Requirement already satisfied: EasyProcess in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyvirtualdisplay) (0.3)\n",
      "Requirement already satisfied: dm-acme in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (1.21.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (1.0.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (0.1.6)\n",
      "Requirement already satisfied: dm-env in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (1.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-acme) (8.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\jhsib\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from absl-py->dm-acme) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio\n",
    "!pip install PILLOW\n",
    "!pip install pyglet\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install dm-acme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41b705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405a90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "from Game.AI.Ai import AI\n",
    "from Game.Board import GameBoard\n",
    "from Game.PlayerEnum import PlayerTurn\n",
    "from Game.AI.ReinforcementAgent import ReinforcementAI\n",
    "from Core.Index import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e73307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac5320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=8, activation='relu', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(Dense(16, activation='sigmoid', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e6823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compete_models(model1, model2) -> tuple[bool, GameBoard]:\n",
    "    \"\"\"If this is true player1 won, otherwise player 2 won\"\"\"\n",
    "    \n",
    "    # Black player\n",
    "    agent1 = ReinforcementAI(model=model1)\n",
    "    \n",
    "    # White player\n",
    "    agent2 = ReinforcementAI(model=model2)\n",
    "    \n",
    "    #Create game items\n",
    "    game_board = GameBoard()\n",
    "    \n",
    "    print(\"Game Start\")\n",
    "\n",
    "    # Actual gameplay\n",
    "    while game_board.get_winner() is None:\n",
    "        if game_board.current_turn == PlayerTurn.BLACK:\n",
    "            move = agent1.generate_move(game_board)\n",
    "        if game_board.current_turn == PlayerTurn.WHITE:\n",
    "            move = agent2.generate_move(game_board)\n",
    "        x, y = Index.from_zero_based(move[0]), Index.from_zero_based(move[1])\n",
    "        game_board.place(x, y)\n",
    "        \n",
    "    # After game is complete\n",
    "    print(\"Game Complete\")\n",
    "    return game_board.get_winner() == PlayerTurn.BLACK, game_board\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Generation 0\n",
      "Player 0 vs Player 1\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 2\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 3\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 4\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 5\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 6\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 0, 8: 0, 9: 0}\n",
      "Player 0 vs Player 7\n",
      "Game Start\n",
      "Game Complete\n",
      "Score: {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0}\n",
      "Player 0 vs Player 8\n",
      "Game Start\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Training the agent\"\"\"\n",
    "\n",
    "NO_PLAYERS = 10\n",
    "GENERATIONS = 5\n",
    "TOP_X = 4\n",
    "TOP_NAME = \"./player_model\"\n",
    "\n",
    "# Create Both Players\n",
    "top_player = load_model(TOP_NAME)\n",
    "players = [top_player] + [create_new_model() for _ in range(NO_PLAYERS - 1)]\n",
    "\n",
    "for generation in range(GENERATIONS):\n",
    "    \n",
    "    print(f\"Training Generation {generation}\")\n",
    "    \n",
    "    # Score board to keep track\n",
    "    score = {}\n",
    "    for n in range(NO_PLAYERS):\n",
    "        score[n] = 0\n",
    "    \n",
    "    # Compete players with one another\n",
    "    for m1 in range(NO_PLAYERS):\n",
    "        for m2 in range(m1 + 1, NO_PLAYERS):\n",
    "            print(f\"Player {m1} vs Player {m2}\")\n",
    "            p1 = players[m1]\n",
    "            p2 = players[m2]\n",
    "            winner, board = compete_models(p1, p2)\n",
    "            if winner:\n",
    "                score[m1] += 1\n",
    "            else:\n",
    "                score[m2] += 1\n",
    "            print(f\"Score: {score}\")\n",
    "    \n",
    "    # Get the player with the highest score\n",
    "    sorted_index = sorted(\n",
    "                tuple(\n",
    "                    map(\n",
    "                        tuple,\n",
    "                        score.items()\n",
    "                    )\n",
    "                ),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )\n",
    "    print(f\"Sorted Index: {sorted_index}\")\n",
    "    sorted_players = list(\n",
    "        map(\n",
    "            lambda x: players[x[0]],\n",
    "            sorted_index\n",
    "        )\n",
    "    )[:TOP_X]\n",
    "    players = sorted_players + [create_new_model() for _ in range(NO_PLAYERS - len(sorted_players))]\n",
    "    \n",
    "# Save the file of the top player\n",
    "top = players[0]\n",
    "top.save(TOP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864009a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
